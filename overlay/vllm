#!/usr/bin/env bash
set -euo pipefail

# vllm-stack calls: vllm serve <model> --host ... --port ...
if [[ "${1:-}" == "serve" ]]; then
  shift
  MODEL="${1:-}"
  if [[ -n "${MODEL:-}" && "${MODEL}" != --* ]]; then
    shift
    export MODEL_NAME="${MODEL_NAME:-$MODEL}"
  fi
fi

HOST="${HOST:-0.0.0.0}"
PORT="${PORT:-8000}"

while [[ $# -gt 0 ]]; do
  case "$1" in
    --host) HOST="$2"; shift 2 ;;
    --port) PORT="$2"; shift 2 ;;
    --gpu_memory_utilization|--gpu-memory-utilization)
      export GPU_MEMORY_UTILIZATION="$2"
      shift 2
      ;;
    *) shift ;;
  esac
done

export HOST PORT
cd /app
exec python -m uvicorn server:app --host "$HOST" --port "$PORT" --log-level info
